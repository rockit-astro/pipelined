#!/usr/bin/env python3.4
#
# This file is part of pipelined.
#
# pipelined is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# pipelined is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with pipelined.  If not, see <http://www.gnu.org/licenses/>.

"""Daemon for the Warwick one-metre telescope frame pipeline"""

# pylint: disable=too-few-public-methods
# pylint: disable=no-self-use
# pylint: disable=broad-except
# pylint: disable=invalid-name
# pylint: disable=too-many-instance-attributes
# pylint: disable=too-many-locals
# pylint: disable=too-many-statements
# pylint: disable=too-many-lines
# pylint: disable=too-many-nested-blocks

import datetime
import json
import math
import os
import pathlib
import queue
import re
import shutil
import subprocess
import tempfile
import threading
import numpy
import sep
from astropy.io import fits
import astropy.table
import pyds9
from PIL import Image, ImageOps
import Pyro4
from warwick.observatory.common import (
    daemons,
    log,
    IP,
    helpers,
    TryLock)
from warwick.observatory.common.helpers import pyro_client_matches

# Set automatically when generating RPM package
SOFTWARE_VERSION = 'UNKNOWN'

# Maximum time to block the camera waiting to hand a frame to the processing thread
MAX_NOTIFY_WAIT = 10

# Timeout for telescope / environment status queries
STATUS_QUERY_TIMEOUT = 1

BASE_DATA_PATH = pathlib.Path('/home/ops/OBS_DATA/')
PIXELSHIFT_PATH = '/home/ops/src/pixelshift/pixelshift'

GUIDE_REFERENCE_FRAME_PATH = '/var/tmp/guide_reference.fits'

# Configuration cache
CONFIG_PATH = '/var/tmp/pipeline.json'

CONTROL_IPS = [IP.OneMetreDome, IP.OneMetreTCS]
NOTIFY_FRAME_IPS = [IP.OneMetreTCS]

# Matrix coefficients transforming pixel offsets to sky offsets.
# These are just the [CD1_1, CD1_2, CD2_1, CD2_2] wcs parameters
GUIDE_TRANSFORM_MATRICES = {
    'BLUE': [0.000108685545277, -3.58470982799E-07,
             -2.98097156944E-07, -0.000108607868069],
    'RED': [-0.00010858955941, 1.83797853216E-07,
            -2.66674559873E-07, -0.000108601351771]
}

CAMERA_URLS = {
    'BLUE': daemons.onemetre_blue_camera,
    'RED': daemons.onemetre_red_camera
}

CAMERAS = ['BLUE', 'RED']

GUIDE_FUDGE_FACTOR = 0.5

# Time limit (seconds) allowed to solve the WCS coordinates of a preview frame
WCS_LIMIT = 4.0

# Maximum field size (arcmin)
# Note that this needs to account for the overscan too!
WCS_SCALE_HIGH = 13.7

# Maximum tcs ra/dec error (degrees)
WCS_SEARCH_RADIUS = 1.75

# Unbinned arcseconds per pixel
OBJECT_PLATESCALE = 0.391

# Minimum number of pixels for considering a source for FWHM estimation
OBJECT_MINPIX = 16

# Top/bottom margin (in px) to offset the annotation labels
ANNOTATION_LABEL_MARGIN = 30

ANNOTATION_LABEL = 'image; text {} {} #color=green font="helvetica 12 bold" text="{}" select=0'

ENVIRONMENT_KEYS = [
    ('vaisala', 'temperature', 'EXTTEMP', '[deg c] temperature outside dome'),
    ('vaisala', 'relative_humidity', 'EXTHUMD', '[%] humidity outside dome'),
    ('vaisala', 'pressure', 'PRESSURE', '[hPa] air pressure'),
    ('vaisala', 'wind_speed', 'WINDSPD', '[m/s] wind speed outside dome'),
    ('vaisala', 'median_wind_speed', 'MEDWIND', '[m/s] median wind speed (last 20 min)'),
    ('roomalert', 'internal_temp', 'DOMETEMP', '[deg c] temperature inside dome'),
    ('roomalert', 'internal_humidity', 'DOMEHUMD', '[%] humidity inside dome'),
    ('roomalert', 'truss_temp', 'TRUSTEMP', '[deg c] temperature at top of telescope truss'),
    ('superwasp', 'sky_temp', 'SKYTEMP', '[deg c] sky temperature'),
    ('vaisala', 'dew_point_delta', 'DEWDELTA', '[deg c] temperature above dew point'),
    ('tng', 'dust', 'TNGDUST', '[ug/m3] TNG Dust measurement'),
    ('power', 'light', 'DOMELITE', 'dome light is powered'),
]

# TODO: Include environment daemon software versions, wind direction, TNG seeing

# This should be kept in sync with the dictionary in pipeline
class CommandStatus:
    """Numeric return codes"""
    # General error codes
    Succeeded = 0
    Failed = 1
    Blocked = 2
    InvalidControlIP = 10
    ReferenceFrameError = 31
    DirectoryNotWritable = 50
    NewDirectoryFailed = 51

def rescale_image_data(data, clip_low, clip_high):
    """ Returns a normalised array where clip_low percent of the pixels are 0 and
        clip_high percent of the pixels are 255
    """
    high = numpy.percentile(data, clip_high)
    low = numpy.percentile(data, clip_low)
    scale = 255. / (high - low)
    data = numpy.clip(data, low, high)
    return scale * (data - low)

class PipelineDaemon:
    """Daemon interface for data pipeline"""
    def __init__(self):
        self._command_lock = threading.Lock()
        self._guide_condition = threading.Condition()
        self._guide_camera_id = None
        self._guide_latest_frame = None
        self._guide_x_binning = 1
        self._guide_y_binning = 1
        self._guide_cos_dec = 1
        self._guide_background_tile_size = 0
        self._guide_reference_frame = None

        guide_thread = threading.Thread(target=self.__process_guide_frames)
        guide_thread.daemon = True
        guide_thread.start()

        self._process_queue = {}
        for cam in CAMERAS:
            self._process_queue[cam] = queue.Queue(maxsize=1)
            thread = threading.Thread(target=self.__process_frames, args=[cam])
            thread.daemon = True
            thread.start()

        # Tuple of (camera, frame, messages)
        self._preview_data = queue.Queue()
        preview_thread = threading.Thread(target=self.__process_previews)
        preview_thread.daemon = True
        preview_thread.start()

        self._wcs_enabled = False
        self._fwhm_enabled = False
        self._intensity_stats_enabled = False
        self._dashboard_enabled = True
        self._compression_enabled = False

        # Information for building the output filename
        self._output_directory = BASE_DATA_PATH
        self._output_frame_prefix = 'unknown'

        self._frame_object = ''
        self._frame_type = 'JUNK'

        self._output_frame_number = {}
        self._output_save_to_disk = {}
        self._ds9_preview_addresses = {}
        for cam in CAMERAS:
            self._output_frame_number[cam] = 0
            self._output_save_to_disk[cam] = False
            self._ds9_preview_addresses[cam] = []

        # Min and max percentage thresholds to use for the preview pngs
        self._dashboard_min_threshold = 5
        self._dashboard_max_threshold = 95
        self._dashboard_thumb_size = 512

        try:
            with open(CONFIG_PATH, 'r') as infile:
                data = json.load(infile)

                self._guide_camera_id = data['guide_camera_id']
                self._guide_background_tile_size = data['guide_background_tile_size']

                self._wcs_enabled = data['wcs_enabled']
                self._fwhm_enabled = data['fwhm_enabled']
                self._intensity_stats_enabled = data['intensity_stats_enabled']
                self._dashboard_enabled = data['dashboard_enabled']
                self._compression_enabled = data['compression_enabled']

                # Information for building the output filename
                self._output_directory = pathlib.Path(data['output_directory'])
                self._output_frame_prefix = data['output_frame_prefix']

                self._frame_object = data['frame_object']
                self._frame_type = data['frame_type']

                for cam in CAMERAS:
                    self._output_frame_number[cam] = data[cam+'_output_frame_number']
                    self._output_save_to_disk[cam] = data[cam+'_output_save_to_disk']
                    self._ds9_preview_addresses[cam] = data[cam+'_ds9_preview_addresses']

                # Min and max percentage thresholds to use for the preview pngs
                self._dashboard_min_threshold = data['dashboard_min_threshold']
                self._dashboard_max_threshold = data['dashboard_max_threshold']
                self._dashboard_thumb_size = data['dashboard_thumb_size']
        except Exception as e:
            print('failed to load pipeline config with error: ')
            print(e)

        try:
            if self._guide_camera_id is not None:
                self.__load_guide_reference(GUIDE_REFERENCE_FRAME_PATH)
        except Exception as e:
            print('Failed to load guide reference with error: ')
            print(e)

    def __save_config(self):
        """Update the saved config cache on disk"""
        with open(CONFIG_PATH, 'w') as outfile:
            data = {
                'wcs_enabled': self._wcs_enabled,
                'fwhm_enabled': self._fwhm_enabled,
                'intensity_stats_enabled': self._intensity_stats_enabled,
                'dashboard_enabled': self._dashboard_enabled,
                'compression_enabled': self._compression_enabled,

                'output_directory': str(self._output_directory),
                'output_frame_prefix': self._output_frame_prefix,

                'frame_object': self._frame_object,
                'frame_type': self._frame_type,

                'dashboard_min_threshold': self._dashboard_min_threshold,
                'dashboard_max_threshold': self._dashboard_max_threshold,
                'dashboard_thumb_size': self._dashboard_thumb_size,

                'guide_camera_id': self._guide_camera_id,
                'guide_background_tile_size': self._guide_background_tile_size,
            }

            for cam in CAMERAS:
                data.update({
                    cam+'_output_frame_number': self._output_frame_number[cam],
                    cam+'_output_save_to_disk': self._output_save_to_disk[cam],
                    cam+'_ds9_preview_addresses': self._ds9_preview_addresses[cam],
                })

            json.dump(data, outfile)

    def __load_guide_reference(self, path):
        """Loads and initializes the autoguider reference frame"""
        shutil.copy(path, GUIDE_REFERENCE_FRAME_PATH)
        with fits.open(GUIDE_REFERENCE_FRAME_PATH) as reference:
            # pylint: disable=no-member
            self._guide_x_binning = reference[0].header['CCD-XBIN']
            self._guide_y_binning = reference[0].header['CCD-YBIN']
            # pylint: enable=no-member

            # Guide frames are processed in parallel to the regular processing
            # so the telescope header keys may not exist
            # Query the declination from the telescope directly, instead
            with daemons.onemetre_telescope.connect(STATUS_QUERY_TIMEOUT) as teld:
                t = teld.report_status()
                self._guide_cos_dec = math.cos(t['dec'])

        self._guide_reference_frame = GUIDE_REFERENCE_FRAME_PATH

    def __process_guide_frames(self):
        """Calculates image shifts between frames and offsets telescope to compensate"""
        while True:
            # Block until a frame is available for processing
            frame = None
            with self._guide_condition:
                while self._guide_latest_frame is None:
                    self._guide_condition.wait()

                frame = self._guide_latest_frame
                self._guide_latest_frame = None

            # New guide session: take a copy of this frame to use as the reference
            if self._guide_reference_frame is None:
                print('taking', frame, 'as new guide reference')
                log.info('pipelined', 'Initializing autoguider')
                try:
                    self.__load_guide_reference(frame)
                    self.__save_config()
                except Exception as e:
                    print('failed with error: ' + str(e))
                    log.error('pipelined', 'Failed to initialize autoguider (' + str(e) + ')')
                continue

            if self._guide_camera_id not in GUIDE_TRANSFORM_MATRICES:
                print('no transform matrix for camera ' + self._guide_camera_id)
                continue

            try:
                # TODO: use Donuts
                output = subprocess.check_output(
                    [PIXELSHIFT_PATH, frame, self._guide_reference_frame,
                     str(self._guide_background_tile_size)], universal_newlines=True, timeout=5)

                t = GUIDE_TRANSFORM_MATRICES[self._guide_camera_id]
                coords = output.split(' ')

                # Measured offset in px
                dx = float(coords[0])
                dy = float(coords[1])

                # First-order approximated offset in ra, dec (degrees)
                dra = (t[0] * dx + t[1] * dy) * self._guide_x_binning / self._guide_cos_dec
                ddec = (t[2] * dx + t[3] * dy) * self._guide_y_binning

                # Calculate actual telescope offset by running offsets through PID loop
                # TODO: This currently only accounts for proportional offsets (no history)
                guide_offset_ra = GUIDE_FUDGE_FACTOR * dra * math.pi / 180
                guide_offset_dec = GUIDE_FUDGE_FACTOR * ddec * math.pi / 180

                # TODO: Check for and drop anomalously large offsets

                print('offset px: {} {}; arcsec: {} {}'.format(dx, dy, 3600 * dra, 3600 * ddec))

                with daemons.onemetre_telescope.connect() as teld:
                    teld.offset_radec_guiding(guide_offset_ra, guide_offset_dec)
            except Exception as e:
                print('failed to update guiding with error: ' + str(e))
                log.error('pipelined', 'Failed to calculate guide offset (' + str(e) + ')')

    def __process_previews(self, unregister_on_error=True):
        """Updates the ds9 preview windows with data from the main processing thread"""
        last_hdulist = None
        while True:
            try:
                # Block until a preview is available
                camera_id, hdulist, xpa_messages = self._preview_data.get()

                # We only care about the last entry
                try:
                    while True:
                        camera_id, hdulist, xpa_messages = self._preview_data.get(block=False)
                except queue.Empty:
                    pass

                for address in self._ds9_preview_addresses[camera_id][:]:
                    try:
                        p = pyds9.DS9(address, start=False, wait=1)
                        if hdulist is not None and hdulist != last_hdulist:
                            p.set_pyfits(hdulist)
                            last_hdulist = hdulist

                        if xpa_messages is not None:
                            for message in xpa_messages:
                                if isinstance(message, tuple):
                                    p.set(message[0], message[1])
                                else:
                                    p.set(message)
                    except Exception as e:
                        if unregister_on_error:
                            self._ds9_preview_addresses[camera_id].remove(address)
                            self.__save_config()
                            print('{}: unregistering preview {}: {}'.format(camera_id, address, e))
            except Exception as e:
                print('unexpected exception when processing ' + camera_id + ' preview')
                print(e)

    def __add_telescope_header(self, frame):
        """Queries the telescope status and adds the appropriate header keys to the frame"""
        h = frame.header
        desc = fits.Card('COMMENT', ' ---          TELESCOPE INFORMATION          --- ')
        h.append(fits.Card(None, None), end=True)
        h.append(desc, end=True)

        try:
            with daemons.onemetre_telescope.connect(STATUS_QUERY_TIMEOUT) as teld:
                t = teld.report_status()
                h.append(fits.Card('TELSWVER', t['software_version'],
                                   'tcs server software version'), end=True)
                h.append(fits.Card('TELSTATE', t['state_label'], 'telescope status'), end=True)
                if t['state'] != 0:
                    harad = t['lst'] - t['ra']
                    while harad > math.pi:
                        harad -= 2*math.pi
                    while harad < -math.pi:
                        harad += 2*math.pi

                    ra = helpers.sexagesimal(t['ra'] * 12 / math.pi)
                    h.append(fits.Card('TELRA', ra, 'telescope nominal J2000 RA'), end=True)
                    dec = helpers.sexagesimal(math.degrees(t['dec']))
                    h.append(fits.Card('TELDEC', dec, 'telescope nominal J2000 Dec'), end=True)
                    ha = helpers.sexagesimal(harad * 12 / math.pi)
                    h.append(fits.Card('TELHA', ha, 'telescope nominal HA'), end=True)
                    rad = round(math.degrees(t['ra']), 3)
                    h.append(fits.Card('TELRAD', rad, '[deg] telescope nominal J2000 RA'), end=True)
                    decd = round(math.degrees(t['dec']), 3)
                    h.append(fits.Card('TELDECD', decd, '[deg] telescope nominal J2000 Dec'),
                             end=True)
                    had = round(math.degrees(harad), 3)
                    h.append(fits.Card('TELHAD', had, '[deg] telescope nominal HA'), end=True)
                    altd = round(math.degrees(t['alt']), 3)
                    h.append(fits.Card('ALTITUDE', altd, '[deg] telescope altitude'), end=True)
                    azd = round(math.degrees(t['az']), 3)
                    h.append(fits.Card('AZIMUTH', azd, '[deg] telescope azimuth'), end=True)
                    h.append(fits.Card('TELFOCUS', t['telescope_focus_um'],
                                       '[um] telescope nominal focus'), end=True)

                if 'site_latitude' in t:
                    lat = helpers.sexagesimal(math.degrees(t['site_latitude']))
                    h.append(fits.Card('SITELAT', lat, 'telescope latitude (north)'), end=True)
                    lon = helpers.sexagesimal(math.degrees(t['site_longitude']))
                    h.append(fits.Card('SITELONG', lon, 'telescope longitude (east)'), end=True)
                    elevation = round(t['site_elevation'], 1)
                    h.append(fits.Card('SITEELEV', elevation, '[m] telescope elevation'), end=True)
        except Exception as e:
            print('failed to add telescope headers with error: ' + str(e))
            log.error('pipelined', 'Failed to query telescope metadata (' + str(e) + ')')
        return h

    def __add_environment_header(self, frame):
        """Queries the environment status and adds the appropriate header keys to the frame"""
        h = frame.header
        desc = fits.Card('COMMENT', ' ---         ENVIRONMENT INFORMATION         --- ')
        h.append(fits.Card(None, None), end=True)
        h.append(desc, end=True)

        try:
            with daemons.onemetre_environment.connect(STATUS_QUERY_TIMEOUT) as environment:
                data = environment.status()
                for (source, sensor, key, comment) in ENVIRONMENT_KEYS:
                    if source not in data or sensor not in data[source]['data']:
                        continue

                    valid = sensor + '_valid'
                    if valid in data[source]['data'] and not data[source]['data'][valid]['latest']:
                        continue
                    h.append(fits.Card(key, data[source]['data'][sensor]['latest'], comment),
                             end=True)
        except Exception as e:
            print('failed to add environment headers with error: ' + str(e))
            log.error('pipelined', 'Failed to query environment metadata (' + str(e) + ')')
        return h

    def __add_pipeline_header(self, camera_id, frame):
        """Adds pipeline configuration to the frame header"""
        desc = fits.Card('COMMENT', ' ---               DATA PIPELINE               --- ')
        frame.header.append(fits.Card(None, None), end=True)
        frame.header.append(desc, end=True)

        filename = ''
        if self._output_save_to_disk[camera_id]:
            ext = '.fits.gz' if self._compression_enabled else '.fits'
            filename = self._output_frame_prefix + '-' + camera_id + \
                '-{:04d}'.format(self._output_frame_number[camera_id]) + ext

        try:
            frame.header.append(fits.Card('DPSWVER', SOFTWARE_VERSION,
                                          'data pipeline software version'), end=True)
            frame.header.append(fits.Card('FILESAVE', self._output_save_to_disk[camera_id],
                                          'image has been archived to disk'), end=True)
            frame.header.append(fits.Card('FILENAME', filename, 'archived image name'), end=True)
            frame.header.append(fits.Card('IMAGETYP', self._frame_type, 'frame type'), end=True)

            if self._frame_type == 'SCIENCE':
                frame.header.append(fits.Card('OBJECT', self._frame_object,
                                              'science target name'), end=True)

        except Exception as e:
            print('failed to add pipeline header with error: ' + str(e))
            return []

    def __add_wcs_header(self, frame, camera_id, objects):
        """Solves frame WCS and adds the appropriate header keys to the frame.
           Returns a list of xpa messages that can be given to __update_previews"""
        if objects is None or len(objects) <= 0:
            return []

        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']

        try:
            table_path = '/var/tmp/' + camera_id + '-scratch.xyls'
            try:
                os.remove(table_path)
            except OSError:
                pass

            astropy.table.Table(objects).write(table_path, format='fits')

            wcs_path = '/var/tmp/' + camera_id + '-scratch.wcs'
            try:
                os.remove(wcs_path)
            except OSError:
                pass

            args = [
                '/usr/local/astrometry/bin/solve-field',
                '--overwrite', '--no-plots',
                '--axy', 'none', '--rdls', 'none', '--match', 'none',
                '--corr', 'none', '--solved', 'none',
                '--scale-units', 'arcminwidth', '--scale-high', str(WCS_SCALE_HIGH),
                '--width', str(width), '--height', str(height),
                '--ra', frame.header['TELRA'], '--dec', frame.header['TELDEC'],
                '--radius', str(WCS_SEARCH_RADIUS), table_path]

            subprocess.check_call(args, timeout=WCS_LIMIT,
                                  stdout=subprocess.DEVNULL,
                                  stderr=subprocess.DEVNULL)

            wcs_data = ''
            wcs_ignore_cards = ['SIMPLE', 'BITPIX', 'NAXIS', 'EXTEND', 'DATE', 'IMAGEW', 'IMAGEH']
            comment = 'astrometry.net wcs solution'
            with open(wcs_path) as wcs_file:
                header = wcs_file.read()
                # ds9 will only accept newline-delimited keys
                # so we need to reformat the 80-character cards
                for line in [header[i:i+80] for i in range(0, len(header), 80)]:
                    key = line[0:8].strip()
                    if '=' in line and key not in wcs_ignore_cards:
                        card = fits.Card.fromstring(line)
                        value = line[9:].split('/')[0].strip()
                        wcs_data += key + ' = ' + value + '\n'

                        frame.header.append(fits.Card(card.keyword, card.value, comment), end=True)
            return [
                ('wcs replace', wcs_data),
                ('regions', ANNOTATION_LABEL.format(width / 5, -ANNOTATION_LABEL_MARGIN,
                                                    'WCS: solved'))
            ]
        except Exception as e:
            print('failed to update wcs with error: ' + str(e))
            return [('regions', ANNOTATION_LABEL.format(width / 4, -ANNOTATION_LABEL_MARGIN,
                                                        'WCS: failed'))]

    def __detect_objects(self, frame):
        """Subtracts the frame background then returns a numpy array of (x, y, flux, fwhm) for each
           object detected by sep"""
        try:
            if frame.header['SHUTTER'] == 'CLOSED':
                return numpy.zeros((0, 4))

            platescale = frame.header['CCD-XBIN'] * OBJECT_PLATESCALE

            # TODO: use Donuts
            image = frame.data.astype(float)
            bkg = sep.Background(image)
            subtracted = image - bkg

            thresh = 5 * bkg.globalrms
            raw_objects = sep.extract(subtracted, thresh)
            objects = []
            for star in raw_objects:
                # Discard spuriously small sources
                if star['npix'] < OBJECT_MINPIX:
                    continue

                x = star['x']
                y = star['y']
                a = star['a']
                b = star['b']
                theta = star['theta']
                kronrad, flag = sep.kron_radius(subtracted, x, y, a, b, theta, 6.0)
                if flag != 0:
                    continue

                flux, _, flag = sep.sum_ellipse(subtracted, x, y, a, b, theta, 2.5 * kronrad,
                                                subpix=0)
                if flag != 0:
                    continue

                r, flag = sep.flux_radius(subtracted, x, y, 6.0 * a, 0.5, normflux=flux, subpix=5)
                if flag != 0:
                    continue

                objects.append((x, y, flux, 2 * r * platescale))

            dtype = [('X', float), ('Y', float), ('FLUX', float), ('FWHM', float)]
            return numpy.array(objects, dtype=dtype)
        except Exception as e:
            print('failed to extract objects with error: ' + str(e))
            return numpy.zeros((0, 4))

    def __add_fwhm_header(self, frame, objects):
        """Adds the median fwhm to the frame header"""
        try:
            if objects is None or len(objects) <= 0:
                return []

            median = round(numpy.median(objects['FWHM']), 2)
            frame.header.append(fits.Card('MEDFWHM', median, '[arcsec] median estimated FWHM'),
                                end=True)
            frame.header.append(fits.Card('FWHMCNT', len(objects),
                                          'number of sources used to estimate FWHM'), end=True)
        except Exception as e:
            print('failed to calculate fwhm with error: ' + str(e))

    def __add_intensity_stats_header(self, frame):
        """Estimates and the median PSF FWHM and returns a list of (x,y,r) tuples that can be
           used for the live preview overlays"""

        try:
            frame.header.append(fits.Card('MEANCNTS', round(numpy.mean(frame.data), 2),
                                          'mean frame counts'), end=True)
            frame.header.append(fits.Card('MEDCNTS', round(numpy.median(frame.data), 2),
                                          'median frame counts'), end=True)
            frame.header.append(fits.Card('STDCNTS', round(numpy.std(frame.data), 2),
                                          'standard deviation of frame counts'), end=True)
        except Exception as e:
            print('failed to calculate intensity stats with error: ' + str(e))
            return []

    def __generate_header_annotations(self, camera_id, frame, objects):
        """Returns the XPA commands to display the time and exposure on the live previews"""
        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']
        date = frame.header['DATE-OBS']
        exptime = frame.header['EXPTIME']
        arm = frame.header['INSTRARM']

        saved = 'SAVED' if self._output_save_to_disk[camera_id] else 'NOT SAVED'
        annotations = [
            ('regions', ANNOTATION_LABEL.format(width / 4, height + ANNOTATION_LABEL_MARGIN, date)),
            ('regions', ANNOTATION_LABEL.format(3 * width / 4, height + ANNOTATION_LABEL_MARGIN,
                                                '{} @ {:.1f}s'.format(arm, exptime))),
            ('regions', ANNOTATION_LABEL.format(width / 2, -ANNOTATION_LABEL_MARGIN, saved))
        ]

        if 'MEDFWHM' in frame.header:
            fwhm_label = ANNOTATION_LABEL.format(
                4 * width / 5, -ANNOTATION_LABEL_MARGIN,
                'FWHM: ' + str(frame.header['MEDFWHM']) + ' arcsec')
            annotations.append(('regions', fwhm_label))

        if objects:
            for o in objects:
                cr = 'image; circle({},{},{}) #select=0 color=red'.format(o[0] + 1, o[1] + 1, o[3])
                annotations.append(('regions', cr))
        return annotations

    def __update_dashboard(self, camera_id, frame):
        try:
            # Trim overscan regions
            r = re.search(r'^\[(\d+):(\d+),(\d+):(\d+)\]$', frame.header['IMAG-RGN']).groups()
            data = frame.data[int(r[2])-1:int(r[3]), int(r[0])-1:int(r[1])]

            fwhm = -1 if 'MEDFWHM' not in frame.header else frame.header['MEDFWHM']
            metadata = {
                'date': frame.header['DATE-OBS'],
                'exptime': frame.header['EXPTIME'],
                'saved': frame.header['FILESAVE'],
                'filename': frame.header['FILENAME'],
                'fwhm': fwhm
            }

            scaled = rescale_image_data(data, self._dashboard_min_threshold,
                                        self._dashboard_max_threshold)
            png = Image.fromarray(scaled).convert('RGB')

            # Red arm flips vertically only
            # Blue arm flips horizontally and vertically
            png = ImageOps.flip(png)
            if camera_id == 'BLUE':
                png = ImageOps.mirror(png)

            png.save('/var/tmp/dashboard-' + camera_id + '.png', 'PNG', clobber=True)
            png.thumbnail((self._dashboard_thumb_size, self._dashboard_thumb_size))
            png.save('/var/tmp/dashboard-' + camera_id + '-thumb.png', 'PNG', clobber=True)
            with open('/var/tmp/dashboard-' + camera_id + '.json', 'w') as outfile:
                json.dump(metadata, outfile)
        except Exception as e:
            print('failed to generate dashboard preview with error: ' + str(e))
            log.error('pipelined', 'Failed to generate dashboard data (' + str(e) + ')')

    def __notify_opsd(self, frame):
        try:
            header = {}
            for card in frame.header.cards:
                if card.is_blank or not card.keyword or card.keyword == 'COMMENT':
                    continue

                header[card.keyword] = card.value

            with daemons.onemetre_operations.connect() as ops:
                ops.notify_processed_frame(header)

        except Exception as e:
            print('failed to notify operations daemon of completed frame with error: ' + str(e))
            log.error('pipelined', 'Failed to notify operations daemon of completed' \
                                  ' frame (' + str(e) + ')')

    def __process_frames(self, camera_id):
        process_queue = self._process_queue[camera_id]
        while True:
            # Blocks until a frame is available for processing
            loadpath = process_queue.get()

            try:
                start = datetime.datetime.utcnow()
                with fits.open(loadpath) as hdulist:
                    frame = hdulist[0]
                    print('loaded frame ' + loadpath)

                    steps = ['headers']
                    self.__add_telescope_header(frame)
                    self.__add_environment_header(frame)
                    self.__add_pipeline_header(camera_id, frame)

                    if self._intensity_stats_enabled:
                        self.__add_intensity_stats_header(frame)
                        steps.append('intstats')

                    objects = None
                    if self._fwhm_enabled or self._wcs_enabled:
                        objects = self.__detect_objects(frame)
                        steps.append('objdetect')

                    if self._fwhm_enabled:
                        self.__add_fwhm_header(frame, objects)
                        steps.append('fwhm')

                    # Update previews before the relatively-slow WCS step
                    annotations = self.__generate_header_annotations(camera_id, frame, objects)
                    self._preview_data.put((camera_id, hdulist, annotations))

                    if self._wcs_enabled:
                        wcs = self.__add_wcs_header(frame, camera_id, objects)
                        self._preview_data.put((camera_id, hdulist, wcs))
                        steps.append('wcs')

                    if self._output_save_to_disk[camera_id]:
                        ext = '.fits.gz' if self._compression_enabled else '.fits'
                        filename = self._output_frame_prefix + '-' + camera_id + \
                            '-{:04d}'.format(self._output_frame_number[camera_id]) + ext
                        savepath = str(self._output_directory / filename)

                        tmp = '.tmp.fits.gz' if self._compression_enabled else '.tmp.fits'
                        tmpname = self._output_frame_prefix + '-' + camera_id + \
                            '-{:04d}'.format(self._output_frame_number[camera_id]) + tmp

                        tmppath = str(self._output_directory / tmpname)

                        # Simulate an atomic write by writing to a temporary file then renaming
                        frame.writeto(tmppath, overwrite=True)
                        shutil.move(tmppath, savepath)

                        print('Saved frame ' + filename)
                        log.info('pipelined', 'Saved frame ' + filename)
                        self._output_frame_number[camera_id] += 1
                        steps.append('compress' if self._compression_enabled else 'save')
                        self.__save_config()

                    if self._dashboard_enabled:
                        self.__update_dashboard(camera_id, frame)
                        steps.append('dashboard')

                    self.__notify_opsd(frame)
                process_time = round((datetime.datetime.utcnow() - start).total_seconds(), 1)
                print('processed ' + loadpath + ' in ' + str(round(process_time, 2)) + 's (' \
                      + ', '.join(steps) + ')')

            except Exception as e:
                print('Unexpected exception while processing ' + loadpath + ': ' + str(e))
            finally:
                try:
                    os.remove(loadpath)
                    print('Deleting temporary frame: ' + loadpath)
                except Exception:
                    print('Failed to delete temporary frame: ' + loadpath)
                process_queue.task_done()

    @Pyro4.expose
    def notify_frame(self, camera_id, path):
        """Called by the camera daemons to notify that a new frame has been saved to disk"""
        if not pyro_client_matches(NOTIFY_FRAME_IPS):
            return CommandStatus.InvalidControlIP

        # Guide offsets should be applied ASAP
        if self._guide_camera_id == camera_id:
            # The guiding only cares about the latest frame
            with self._guide_condition:
                self._guide_latest_frame = path
                self._guide_condition.notify()
            print('updated guide frame', camera_id, path)

        if camera_id not in self._process_queue:
            raise Exception('Unknown camera id ' + camera_id)

        # Block until the processing thread has completed the previous frame.
        # We require a direct hand-off from the camera to the pipeline to prevent accidental
        # backlogs which would desync the real-time processing done by the processing thread.
        process_queue = self._process_queue[camera_id]
        wait_start = datetime.datetime.utcnow()
        process_queue.join()
        process_queue.put(path)
        wait = (datetime.datetime.utcnow() - wait_start).total_seconds()

        if wait > 0.1:
            print('WARNING: ' + camera_id + ' camera blocked for ' + str(wait) + 's by pipeline')
            log.warning('pipelined', camera_id + ' camera blocked for ' + str(wait) + \
                's by pipeline')

    @Pyro4.expose
    def set_guide_camera(self, camera_id, background_tile_size=0, reference_frame=None):
        """Sets the camera ID to use for guiding"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            if reference_frame is not None:
                try:
                    self.__load_guide_reference(reference_frame)
                except Exception as e:
                    print('Failed to load reference frame with error: ')
                    print(e)
                    return CommandStatus.ReferenceFrameError

            self._guide_camera_id = camera_id
            self._guide_background_tile_size = background_tile_size

            if camera_id is not None:
                log.info('pipelined', 'Configured autoguiding with ' + camera_id \
                                     + ' camera and ' + str(background_tile_size) + ' px tiles')
            else:
                log.info('pipelined', 'Disabled autoguiding')
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_archive_directory(self, directory):
        """Sets the output frame directory"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            # Check that the directory exists and is writable
            try:
                path = pathlib.Path(directory).resolve()
                testfile = tempfile.TemporaryFile(dir=str(path))
                self._output_directory = path
                testfile.close()
            except Exception:
                return CommandStatus.DirectoryNotWritable

            log.info('pipelined', 'Frame archive directory set to ' + str(path))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_output_frame_prefix(self, prefix):
        """Sets the output frame prefix"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_frame_prefix = prefix

            log.info('pipelined', 'Frame prefix set to ' + prefix)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_archive(self, camera_id, enabled):
        """Enable or disable archiving to disk"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_save_to_disk[camera_id] = enabled
            log.info('pipelined', 'Frame archiving for ' + camera_id \
                                 + (' enabled' if enabled else ' disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def register_preview(self, camera_id, address):
        """Register a ds9 window for previews"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._ds9_preview_addresses[camera_id].append(address)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_output_frame_number(self, camera_id, number):
        """Sets the output frame number"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_frame_number[camera_id] = int(number)

            log.info('pipelined', 'Frame number for ' + camera_id + ' set to ' + str(number))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_frame_object(self, object_name):
        """Sets the output frame number"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._frame_object = object_name

            log.info('pipelined', 'Frame object set to ' + object_name)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_frame_type(self, frame_type):
        """Sets the output frame number"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._frame_type = frame_type

            log.info('pipelined', 'Frame type set to ' + frame_type)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_min_threshold(self, percent):
        """Sets the minimum contrast percentage for the web dashboard preview"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_min_threshold = percent
        log.info('pipelined', 'Dashboard preview min threshold set to ' + str(percent) + '%')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_max_threshold(self, percent):
        """Sets the maximum contrast percentage for the web dashboard preview"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_max_threshold = percent
        log.info('pipelined', 'Dashboard preview min threshold set to ' + str(percent) + '%')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_thumb_size(self, max_size):
        """Sets the maximum dimension of the web dashboard preview thumbnails"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_thumb_size = max_size
        log.info('pipelined', 'Dashboard preview thumbnail size set to ' + str(max_size) + ' px')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_wcs(self, enabled):
        """Enable or disable wcs solutions"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._wcs_enabled = enabled
            log.info('pipelined', 'WCS solution ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_fwhm(self, enabled):
        """Enable or disable fwhm calculations"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._fwhm_enabled = enabled
            log.info('pipelined', 'FWHM calculation ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_intensity_stats(self, enabled):
        """Enable or disable intensity statistics solutions"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._intensity_stats_enabled = enabled
            log.info('pipelined', 'Intensity statistics ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard(self, enabled):
        """Enable or disable dashboard updates"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._dashboard_enabled = enabled
            log.info('pipelined', 'Dashboard updates ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_compression(self, enabled):
        """Enable or disable gz compression"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._compression_enabled = enabled
            log.info('pipelined', 'Frame compression ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def start_night(self):
        """Creates a new data directory for the current night and resets archive configuration"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            night = (datetime.datetime.utcnow() - datetime.timedelta(hours=12)).strftime('%Y%m%d')
            path = BASE_DATA_PATH / night
            try:
                os.makedirs(str(path))
                self._output_directory = path
            except Exception as e:
                print('failed to create night dir with exception:')
                print(e)
                return CommandStatus.NewDirectoryFailed

            self._output_frame_prefix = 'unknown'
            self._frame_object = ''
            self._frame_type = 'JUNK'

            for cam in CAMERAS:
                self._output_frame_number[cam] = 0
                self._output_save_to_disk[cam] = False
            self._compression_enabled = False
            self.__save_config()

            log.info('pipelined', 'Started new night ' + night)
            return CommandStatus.Succeeded

    @Pyro4.expose
    def report_status(self):
        """Returns a dictionary containing the current pipeline state"""
        next_filename = {}
        ext = '.fits.gz' if self._compression_enabled else '.fits'

        for cam in CAMERAS:
            next_filename[cam] = self._output_frame_prefix + '-' + cam \
                + '-{:04d}'.format(self._output_frame_number[cam]) + ext

        return {
            'guide_camera_id': self._guide_camera_id,
            'guide_background_tile_size': self._guide_background_tile_size,
            'guide_reference_frame': self._guide_reference_frame,

            'wcs_enabled': self._wcs_enabled,
            'fwhm_enabled': self._fwhm_enabled,
            'intensity_stats_enabled': self._intensity_stats_enabled,
            'dashboard_enabled': self._dashboard_enabled,
            'compression_enabled': self._compression_enabled,

            'next_filename': next_filename,
            'archive_enabled': self._output_save_to_disk,
            'archive_directory': str(self._output_directory),

            'dashboard_min_threshold': self._dashboard_min_threshold,
            'dashboard_max_threshold': self._dashboard_max_threshold,
            'dashboard_thumb_size': self._dashboard_thumb_size,

            'frame_type': self._frame_type,
            'frame_object': self._frame_object
        }

if __name__ == '__main__':
    daemons.onemetre_pipeline.launch(PipelineDaemon())
