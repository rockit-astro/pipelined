#!/usr/bin/env python3.6
#
# This file is part of pipelined.
#
# pipelined is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# pipelined is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with pipelined.  If not, see <http://www.gnu.org/licenses/>.

"""Frame pipeline daemon"""

# pylint: disable=no-self-use
# pylint: disable=too-many-branches

import argparse
import array
import datetime
import json
import os
import queue
import re
import shutil
import subprocess
import sys
import tempfile
import threading
import traceback
from astropy.coordinates import Angle
from astropy.io import fits
import astropy.table
import astropy.units as u
import numpy as np
from PIL import Image, ImageOps
import pyds9
import Pyro4
import sep
from warwick.observatory.common import log, TryLock
from warwick.observatory.common.helpers import pyro_client_matches
from warwick.observatory.pipeline import CommandStatus, Config

# Set automatically when generating RPM package
SOFTWARE_VERSION = 'UNKNOWN'

ANNOTATION_LABEL = 'image; text {} {} #color=green font="helvetica 12 bold" text="{}" select=0'


def rescale_image_data(data, clip_low, clip_high):
    """ Returns a normalised array where clip_low percent of the pixels are 0 and
        clip_high percent of the pixels are 255
    """
    high = np.percentile(data, clip_high)
    low = np.percentile(data, clip_low)
    scale = 255. / (high - low)
    data = np.clip(data, low, high)
    return scale * (data - low)


def create_formatted_card(key, value, comment, format_type):
    float_places = {
        'float1dp': 1,
        'float2dp': 2,
        'float5dp': 5
    }

    try:
        if format_type in float_places:
            return create_float_card(key, value, comment, float_places[format_type])

        if format_type == 'int':
            value = int(value)
        elif format_type == 'bool':
            value = bool(value)
        elif format_type == 'sexagesimalha':
            value = Angle(value * u.deg).to(u.hourangle).to_string(sep=':', precision=2)
        elif format_type == 'sexagesimaldeg':
            value = Angle(value * u.deg).to_string(sep=':', precision=2)

        return fits.Card(key, value, comment)
    except Exception:
        print('failed to create card ' + key + ' with error: ')
        traceback.print_exc(file=sys.stdout)
        return fits.Card('COMMENT', ' ' + key + ' not available', '')


def create_float_card(key, value, comment, places):
    """Create a fits.Card instance with a float value
       rounded to a specified number of significant figures
    """
    fmt = '{:8s}= {:.0' + str(places) + 'f}'
    card = fits.Card.fromstring(fmt.format(key, value))
    card.comment = comment
    return card


def header_to_dict(header):
    ret = {}
    for card in header.cards:
        if card.is_blank or not card.keyword or card.keyword == 'COMMENT':
            continue

        ret[card.keyword] = card.value
    return ret


class PipelineDaemon:
    """Daemon interface for data pipeline"""
    def __init__(self, config):
        self._config = config
        self._command_lock = threading.Lock()
        self._guide_condition = threading.Condition()
        self._guide_latest_frame = None
        self._guide_camera_id = None

        guide_thread = threading.Thread(target=self.__process_guide_frames)
        guide_thread.daemon = True
        guide_thread.start()

        self._process_queue = {}
        for cam in config.cameras:
            self._process_queue[cam] = queue.Queue(maxsize=1)
            thread = threading.Thread(target=self.__process_frames, args=[cam])
            thread.daemon = True
            thread.start()

        # Tuple of (camera, frame, messages)
        self._preview_data = queue.Queue()
        preview_thread = threading.Thread(target=self.__process_previews)
        preview_thread.daemon = True
        preview_thread.start()

        self._wcs_enabled = False
        self._hfd_enabled = False
        self._intensity_stats_enabled = False
        self._dashboard_enabled = True

        # Information for building the output filename
        self._output_directory = config.data_root_path
        self._output_frame_prefix = 'unknown'

        self._frame_object = ''
        self._frame_type = 'JUNK'

        self._output_save_to_disk = {}
        self._ds9_preview_addresses = {}
        for cam in config.cameras:
            self._output_save_to_disk[cam] = False
            self._ds9_preview_addresses[cam] = []

    def __process_guide_frames(self):
        """Calculates image shifts between frames and offsets telescope to compensate"""
        while True:
            # Block until a frame is available for processing
            with self._guide_condition:
                while self._guide_latest_frame is None:
                    self._guide_condition.wait()

                frame_path = self._guide_latest_frame
                config = self._config.cameras[self._guide_camera_id]
                self._guide_latest_frame = None

            # Background-subtract and collapse into x/y profiles
            with fits.open(frame_path) as frame:
                frame_data = frame[0].data
                if config['image_region_card']:
                    image_region = frame[0].header[config['image_region_card']]
                    r = re.search(r'^\[(\d+):(\d+),(\d+):(\d+)\]$', image_region).groups()
                    frame_data = frame_data[int(r[2]) - 1:int(r[3]), int(r[0]) - 1:int(r[1])]

                frame_data = frame_data.astype(float)
                background = sep.Background(frame_data)
                background.subfrom(frame_data)

                # Pyro doesn't support numpy arrays, so convert to a built-in type
                profile_x = array.array('f', np.mean(frame_data, axis=0))
                profile_y = array.array('f', np.mean(frame_data, axis=1))

            # Notify opsd
            try:
                with self._config.ops_daemon.connect() as ops:
                    ops.notify_guide_profiles(header_to_dict(frame[0].header), profile_x, profile_y)
            except Exception as e:
                log.error(self._config.log_name,
                          'Failed to notify operations daemon of guide profiles (' + str(e) + ')')

    def __set_archive_directory(self, path):
        """Attempts to set the output data directory
           If path is 'default' a YYYYMMDD night directory will be created in the BASE_DATA_PATH
           otherwise, the given path will be checked to ensure it is writable
           Returns a CommandStatus indicating the result
        """
        try:
            if path == 'default':
                # Default to a night directory in the base data dir
                # Directory will be created if required
                night = (datetime.datetime.utcnow() - datetime.timedelta(hours=12))
                path = os.path.join(self._config.data_root_path, night.strftime('%Y%m%d'))
                try:
                    os.makedirs(path, exist_ok=True)
                except FileExistsError:
                    pass
                except Exception:
                    print('failed to create night dir with exception:')
                    traceback.print_exc(file=sys.stdout)
                    return CommandStatus.NewDirectoryFailed

            # Throws on error
            with tempfile.TemporaryFile(dir=path):
                self._output_directory = path
                return CommandStatus.Succeeded
        except Exception:
            return CommandStatus.DirectoryNotWritable

    def __process_previews(self, unregister_on_error=True):
        """Updates the ds9 preview windows with data from the main processing thread"""
        last_frame = None
        while True:
            # Block until a preview is available
            camera_id, frame, xpa_messages = self._preview_data.get()

            # We only care about the last entry
            try:
                while True:
                    camera_id, frame, xpa_messages = self._preview_data.get(block=False)
            except queue.Empty:
                pass

            try:
                for address in self._ds9_preview_addresses[camera_id][:]:
                    try:
                        p = pyds9.DS9(address, start=False, wait=1)
                        if frame is not None and frame != last_frame:
                            p.set_pyfits(fits.HDUList(frame))
                            last_frame = frame

                        if xpa_messages is not None:
                            for message in xpa_messages:
                                if isinstance(message, tuple):
                                    p.set(message[0], message[1])
                                else:
                                    p.set(message)
                    except Exception as e:
                        if unregister_on_error:
                            self._ds9_preview_addresses[camera_id].remove(address)
                            print('{}: unregistering preview {}: {}'.format(camera_id, address, e))
            except Exception:
                print('unexpected exception when processing ' + camera_id + ' preview')
                traceback.print_exc(file=sys.stdout)

    def __move_bscale_bzero(self, frame):
        """Moves the BSCALE and BZERO header keys to the start of the header
           to be grouped with the other image keywords"""
        frame.header.set('BSCALE', frame.header['BSCALE'], after='NAXIS2')
        frame.header.set('BZERO', frame.header['BZERO'], after='BSCALE')

    def __add_telescope_header(self, frame):
        """Queries the telescope status and adds the appropriate header keys to the frame"""
        desc = fits.Card('COMMENT', ' ---          TELESCOPE INFORMATION          --- ')
        frame.header.append(fits.Card(None, None), end=True)
        frame.header.append(desc, end=True)

        data = {}
        # Query data from daemons
        for config in self._config.telescope_cards:
            key = config['daemon'].uri + '_' + config['method']
            if key in data:
                continue

            try:
                with config['daemon'].connect(self._config.telescope_query_timeout) as daemon:
                    data[key] = getattr(daemon, config['method'])()
            except Exception as e:
                print('failed to add telescope headers with error: ')
                traceback.print_exc(file=sys.stdout)
                log.error(self._config.log_name, 'Failed to query telescope metadata (' + str(e) + ')')
                data[config['daemon']] = {'data': {}}

        # Build cards
        for config in self._config.telescope_cards:
            key = config['daemon'].uri + '_' + config['method']
            value = data.get(key, {}).get(config['parameter'], None)
            if value is not None:
                frame.header.append(create_formatted_card(config['key'], value, config['comment'], config['type']),
                                    end=True)
            else:
                frame.header.append(fits.Card('COMMENT', ' ' + config['key'] + ' not available', ''), end=True)

    def __add_environment_header(self, frame):
        """Queries the environment status and adds the appropriate header keys to the frame"""
        desc = fits.Card('COMMENT', ' ---         ENVIRONMENT INFORMATION         --- ')
        frame.header.append(fits.Card(None, None), end=True)
        frame.header.append(desc, end=True)

        try:
            with self._config.environment_daemon.connect(self._config.environment_query_timeout) as environment:
                data = environment.status()
        except Exception as e:
            data = {}
            print('failed to query environment headers with error: ')
            traceback.print_exc(file=sys.stdout)
            log.error(self._config.log_name, 'Failed to query environment metadata (' + str(e) + ')')

        for config in self._config.environment_cards:
            sensor_data = data.get(config['sensor'], {}).get('parameters', {}).get(config['parameter'], {})
            if sensor_data and sensor_data.get('current', False):
                frame.header.append(create_formatted_card(config['key'], sensor_data['latest'],
                                                          config['comment'], config['type']), end=True)
            else:
                frame.header.append(fits.Card('COMMENT', ' ' + config['key'] + ' not available', ''), end=True)

        return frame.header

    def __add_pipeline_header(self, camera_id, frame, filename):
        """Adds pipeline configuration to the frame header"""
        desc = fits.Card('COMMENT', ' ---               DATA PIPELINE               --- ')
        frame.header.append(fits.Card(None, None), end=True)
        frame.header.append(desc, end=True)

        try:
            frame.header.append(fits.Card('DPSWVER', SOFTWARE_VERSION,
                                          'data pipeline software version'), end=True)
            frame.header.append(fits.Card('FILESAVE', self._output_save_to_disk[camera_id],
                                          'image has been archived to disk'), end=True)

            if self._output_save_to_disk[camera_id]:
                frame.header.append(fits.Card('FILENAME', filename, 'archived image name'), end=True)
            else:
                frame.header.append(fits.Card('COMMENT', ' FILENAME not available', ''))

            frame.header.append(fits.Card('IMAGETYP', self._frame_type, 'frame type'), end=True)

            if self._frame_type == 'SCIENCE':
                frame.header.append(fits.Card('OBJECT', self._frame_object,
                                              'science target name'), end=True)

        except Exception:
            print('failed to add pipeline header with error: ')
            traceback.print_exc(file=sys.stdout)

    def __add_wcs_header(self, frame, camera_id, objects):
        """Solves frame WCS and adds the appropriate header keys to the frame.
           Returns a list of xpa messages that can be given to __update_previews"""
        if objects is None or len(objects) <= 0:
            return []

        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']

        try:
            table_path = '/var/tmp/' + camera_id + '-scratch.xyls'
            try:
                os.remove(table_path)
            except OSError:
                pass

            astropy.table.Table(objects).write(table_path, format='fits')

            wcs_path = '/var/tmp/' + camera_id + '-scratch.wcs'
            try:
                os.remove(wcs_path)
            except OSError:
                pass

            config = self._config.cameras[camera_id]
            wcs_args = [
                '/usr/local/astrometry/bin/solve-field',
                '--overwrite', '--no-plots',
                '--axy', 'none', '--rdls', 'none', '--match', 'none',
                '--corr', 'none', '--solved', 'none',
                '--scale-units', 'arcsecperpix', '--scale-high', str(config['wcs_scale_high']),
                '--scale-low', str(config['wcs_scale_low']), '--width', str(width), '--height', str(height)]

            ra = config.get('wcs_search_ra_card', None)
            dec = config.get('wcs_search_dec_card', None)
            radius = config.get('wcs_search_radius', None)
            if ra and ra in frame.header and dec and dec in frame.header and radius and radius:
                wcs_args.extend([
                    '--ra', frame.header[ra],
                    '--dec', frame.header[dec],
                    '--radius', str(radius)
                ])

            wcs_args.append(table_path)

            subprocess.check_call(wcs_args, timeout=config['wcs_timeout'],
                                  stdout=subprocess.DEVNULL,
                                  stderr=subprocess.DEVNULL)

            wcs_data = ''
            wcs_ignore_cards = ['SIMPLE', 'BITPIX', 'NAXIS', 'EXTEND', 'DATE', 'IMAGEW', 'IMAGEH']
            comment = 'astrometry.net wcs solution'
            with open(wcs_path) as wcs_file:
                header = wcs_file.read()
                # ds9 will only accept newline-delimited keys
                # so we need to reformat the 80-character cards
                for line in [header[i:i+80] for i in range(0, len(header), 80)]:
                    key = line[0:8].strip()
                    if '=' in line and key not in wcs_ignore_cards:
                        card = fits.Card.fromstring(line)
                        value = line[9:].split('/')[0].strip()
                        wcs_data += key + ' = ' + value + '\n'

                        frame.header.append(fits.Card(card.keyword, card.value, comment), end=True)
            return [
                ('wcs replace', wcs_data),
                ('regions', ANNOTATION_LABEL.format(width / 5, -config['preview_ds9_annotation_margin'],
                                                    'WCS: SOLVED'))
            ]
        except Exception as e:
            print('failed to update wcs with error: ' + str(e))
            return [('regions', ANNOTATION_LABEL.format(width / 4, -config['preview_ds9_annotation_margin'],
                                                        'WCS: FAILED'))]

    def __detect_objects(self, camera_id, frame):
        """Subtracts the frame background then returns a numpy array of (x, y, flux, hfd) for each
           object detected by sep"""
        try:
            config = self._config.cameras[camera_id]

            platescale = config['platescale']
            ccd_bin = config.get('ccd_bin_card', None)
            if ccd_bin and ccd_bin in frame.header:
                platescale *= frame.header[ccd_bin]

            image = frame.data.astype(float)
            bkg = sep.Background(image)
            bkg.subfrom(image)

            thresh = 5 * bkg.globalrms
            raw_objects = sep.extract(image, thresh)
            objects = []
            for star in raw_objects:
                # Discard spuriously small sources
                if star['npix'] < config['object_minpix']:
                    continue

                x = np.array([star['x']])
                y = np.array([star['y']])
                a = np.array([star['a']])
                b = np.array([star['b']])

                try:
                    # TODO: Do this for all objects in parallel
                    theta = np.array([star['theta']])
                    kronrad, flag = sep.kron_radius(image, x, y, a, b, theta, 6.0)
                    if flag != 0:
                        continue

                    flux, _, flag = sep.sum_ellipse(image, x, y, a, b, theta, 2.5 * kronrad,
                                                    subpix=0)
                    if flag != 0:
                        continue

                    r, flag = sep.flux_radius(image, x, y, 6.0 * a, 0.5, normflux=flux, subpix=5)
                    if flag != 0:
                        continue

                    objects.append((x.item(), y.item(), flux, 2 * r * platescale))
                except Exception:
                    # Ignore errors in individual objects
                    pass

            # TODO: Replace with Astropy table
            dtype = [('X', float), ('Y', float), ('FLUX', float), ('HFD', float)]
            return np.array(sorted(objects, key=lambda o: -o[2]), dtype=dtype)
        except Exception:
            print('failed to extract objects with error: ')
            traceback.print_exc(file=sys.stdout)
            return np.zeros((0, 4))

    def __add_hfd_header(self, frame, objects):
        """Adds the median hfd to the frame header"""
        try:
            if objects is None or len(objects) <= 0:
                return

            frame.header.append(create_float_card('MEDHFD', np.median(objects['HFD']).item(),
                                                  '[arcsec] median estimated half-flux diameter', 1), end=True)
            frame.header.append(fits.Card('HFDCNT', len(objects),
                                          'number of sources used to estimate the HFD'), end=True)
        except Exception:
            print('failed to calculate HFD with error:')
            traceback.print_exc(file=sys.stdout)

    def __add_intensity_stats_header(self, frame):
        """Adds the frame intensity to the frame header"""
        try:
            frame.header.append(create_float_card('MEANCNTS', np.mean(frame.data),
                                                  'mean frame counts', 2), end=True)
            frame.header.append(create_float_card('MEDCNTS', np.median(frame.data),
                                                  'median frame counts', 2), end=True)
            frame.header.append(create_float_card('STDCNTS', np.std(frame.data),
                                                  'standard deviation of frame counts', 2), end=True)
        except Exception:
            print('failed to calculate intensity stats with error: ')
            traceback.print_exc(file=sys.stdout)

    def __generate_header_annotations(self, camera_id, frame, objects):
        """Returns the XPA commands to display the time and exposure on the live previews"""
        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']
        date = frame.header['DATE-OBS']
        exptime = frame.header['EXPTIME']
        config = self._config.cameras[camera_id]

        saved = 'SAVED' if self._output_save_to_disk[camera_id] else 'NOT SAVED'
        annotations = [
            ('regions', ANNOTATION_LABEL.format(width / 4, height + config['preview_ds9_annotation_margin'], date)),
            ('regions', ANNOTATION_LABEL.format(3 * width / 4, height + config['preview_ds9_annotation_margin'],
                                                '{} @ {:.1f}s'.format(camera_id, exptime))),
            ('regions', ANNOTATION_LABEL.format(width / 2, -config['preview_ds9_annotation_margin'], saved))
        ]

        if 'MEDHFD' in frame.header:
            hfd_label = ANNOTATION_LABEL.format(
                4 * width / 5, -config['preview_ds9_annotation_margin'],
                'HFD: ' + str(frame.header['MEDHFD']) + ' arcsec')
            annotations.append(('regions', hfd_label))


        platescale = config['platescale']
        if objects is not None and len(objects) > 0:
            for o in objects:
                cr = 'image; circle({},{},{}) #select=0 color=red'.format(o[0] + 1, o[1] + 1, o[3] / platescale)
                annotations.append(('regions', cr))

        return annotations

    def __update_dashboard(self, camera_id, frame):
        try:
            config = self._config.cameras[camera_id]

            # Trim overscan regions
            data = frame.data
            if config['image_region_card']:
                image_region = frame.header[config['image_region_card']]
                r = re.search(r'^\[(\d+):(\d+),(\d+):(\d+)\]$', image_region).groups()
                data = data[int(r[2]) - 1:int(r[3]), int(r[0]) - 1:int(r[1])]

            hfd = -1 if 'MEDHFD' not in frame.header else frame.header['MEDHFD']
            metadata = {
                'date': frame.header['DATE-OBS'],
                'exptime': frame.header['EXPTIME'],
                'saved': frame.header['FILESAVE'],
                'filename': frame.header['FILENAME'] if 'FILENAME' in frame.header else '',
                'hfd': hfd
            }

            scaled = rescale_image_data(data, config['dashboard_min_threshold'], config['dashboard_max_threshold'])
            preview = Image.fromarray(scaled).convert('RGB')

            # Red arm flips vertically only
            # Blue arm flips horizontally and vertically
            preview = ImageOps.flip(preview)
            if camera_id == 'BLUE':
                preview = ImageOps.mirror(preview)

            preview.thumbnail((config['dashboard_thumb_size'], config['dashboard_thumb_size']))
            thumb_path = os.path.join(self._config.dashboard_output_path, 'dashboard-' + camera_id + '-thumb.jpg')
            preview.save(thumb_path, 'JPEG', quality=80, optimize=True, progressive=True, clobber=True)

            # Clip the central region from the image
            cx1 = (data.shape[0] - config['dashboard_clip_size']) // 2
            cx2 = cx1 + config['dashboard_clip_size']
            cy1 = (data.shape[1] - config['dashboard_clip_size']) // 2
            cy2 = cy1 + config['dashboard_clip_size']

            clipped = rescale_image_data(data[cx1:cx2, cy1:cy2],
                                         config['dashboard_min_threshold'],
                                         config['dashboard_max_threshold'])
            preview = Image.fromarray(clipped).convert('RGB')
            preview = ImageOps.flip(preview)
            clip_path = os.path.join(self._config.dashboard_output_path, 'dashboard-' + camera_id + '-clip.jpg')
            preview.save(clip_path, 'JPEG', quality=40, optimize=True, progressive=True, clobber=True)

            json_path = os.path.join(self._config.dashboard_output_path, 'dashboard-' + camera_id + '.json')
            with open(json_path, 'w') as outfile:
                json.dump(metadata, outfile)
        except Exception as e:
            print('failed to generate dashboard preview with error:')
            traceback.print_exc(file=sys.stdout)
            log.error(self._config.log_name, 'Failed to generate dashboard data (' + str(e) + ')')

    def __notify_opsd(self, frame):
        try:
            with self._config.ops_daemon.connect() as ops:
                ops.notify_processed_frame(header_to_dict(frame.header))

        except Exception as e:
            print('failed to notify operations daemon of completed frame with error:')
            traceback.print_exc(file=sys.stdout)
            log.error(self._config.log_name, 'Failed to notify operations daemon of completed frame (' + str(e) + ')')

    def __process_frames(self, camera_id):
        process_queue = self._process_queue[camera_id]
        while True:
            # Blocks until a frame is available for processing
            loadpath = process_queue.get()

            try:
                start = datetime.datetime.utcnow()
                with fits.open(loadpath) as hdulist:
                    # Take a copy of the primary HDU so that it remains
                    # available in memory after the file has been closed
                    frame = fits.PrimaryHDU(hdulist[0].data, hdulist[0].header)
                    print('loaded frame ' + loadpath)

                    steps = ['headers']
                    filename = ''
                    if self._output_save_to_disk[camera_id]:
                        date = datetime.datetime.strptime(frame.header['DATE-OBS'],
                                                          '%Y-%m-%dT%H:%M:%S.%f')
                        filename = self._output_frame_prefix + '-' + camera_id + '-' + \
                            date.strftime('%Y%m%d%H%M%S%f')[:-3] + '.fits'

                    self.__move_bscale_bzero(frame)
                    self.__add_telescope_header(frame)
                    self.__add_environment_header(frame)
                    self.__add_pipeline_header(camera_id, frame, filename)

                    if self._intensity_stats_enabled:
                        self.__add_intensity_stats_header(frame)
                        steps.append('intstats')

                    objects = None
                    if self._hfd_enabled or self._wcs_enabled:
                        objects = self.__detect_objects(camera_id, frame)
                        steps.append('objdetect')

                    if self._hfd_enabled:
                        self.__add_hfd_header(frame, objects)
                        steps.append('hfd')

                    # Update previews before the relatively-slow WCS step
                    annotations = self.__generate_header_annotations(camera_id, frame, objects)
                    self._preview_data.put((camera_id, frame, annotations))

                    if self._wcs_enabled:
                        wcs = self.__add_wcs_header(frame, camera_id, objects)
                        self._preview_data.put((camera_id, frame, wcs))
                        steps.append('wcs')

                    if self._output_save_to_disk[camera_id]:
                        tmpname = self._output_frame_prefix + '-' + camera_id + '-' + \
                            date.strftime('%Y%m%d%H%M%S%f')[:-3] + '.tmp.fits'

                        tmppath = os.path.join(self._output_directory, tmpname)
                        savepath = os.path.join(self._output_directory, filename)

                        # Simulate an atomic write by writing to a temporary file then renaming
                        frame.writeto(tmppath, overwrite=True)
                        shutil.move(tmppath, savepath)

                        print('Saved frame ' + filename)
                        log.info(self._config.log_name, 'Saved frame ' + filename)

                    if self._dashboard_enabled:
                        self.__update_dashboard(camera_id, frame)
                        steps.append('dashboard')

                    self.__notify_opsd(frame)
                process_time = round((datetime.datetime.utcnow() - start).total_seconds(), 1)
                print('processed ' + loadpath + ' in ' + str(round(process_time, 2)) + 's (' \
                      + ', '.join(steps) + ')')

            except Exception:
                print('Unexpected exception while processing ' + loadpath + ': ')
                traceback.print_exc(file=sys.stdout)
            finally:
                try:
                    os.remove(loadpath)
                    print('Deleting temporary frame: ' + loadpath)
                except Exception:
                    print('Failed to delete temporary frame: ' + loadpath)
                process_queue.task_done()

    @Pyro4.expose
    def notify_frame(self, camera_id, filename):
        """Called by the camera daemons to notify that a new frame has been saved to disk
           filename is specified relative to the incoming_data_path config value."""
        path = os.path.join(self._config.incoming_data_path, filename)
        if not pyro_client_matches(self._config.notify_frame_machines):
            return

        # Guide offsets should be applied ASAP
        if self._guide_camera_id == camera_id:
            # The guiding only cares about the latest frame
            with self._guide_condition:
                self._guide_latest_frame = path
                self._guide_condition.notify()
            print('updated guide frame', camera_id, path)

        if camera_id not in self._process_queue:
            raise Exception('Unknown camera id ' + camera_id)

        # Block until the processing thread has completed the previous frame.
        # We require a direct hand-off from the camera to the pipeline to prevent accidental
        # backlogs which would desync the real-time processing done by the processing thread.
        process_queue = self._process_queue[camera_id]
        wait_start = datetime.datetime.utcnow()
        process_queue.join()
        process_queue.put(path)
        wait = (datetime.datetime.utcnow() - wait_start).total_seconds()

        if wait > 0.1:
            print('WARNING: ' + camera_id + ' camera blocked for ' + str(wait) + 's by pipeline')
            log.warning(self._config.log_name, camera_id + ' camera blocked for ' + str(wait) + 's by pipeline')

    @Pyro4.expose
    def set_archive_directory(self, directory):
        """Sets the output frame directory"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            directory_status = self.__set_archive_directory(directory)
            if directory_status != CommandStatus.Succeeded:
                return directory_status

            log.info(self._config.log_name, 'Frame archive directory set to ' + str(directory))
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_output_frame_prefix(self, prefix):
        """Sets the output frame prefix"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_frame_prefix = prefix

            log.info(self._config.log_name, 'Frame prefix set to ' + prefix)
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_archive(self, camera_id, enabled):
        """Enable or disable archiving to disk"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_save_to_disk[camera_id] = enabled
            log.info(self._config.log_name, 'Frame archiving for ' + camera_id +
                     (' enabled' if enabled else ' disabled'))
            return CommandStatus.Succeeded

    @Pyro4.expose
    def register_preview(self, camera_id, address):
        """Register a ds9 window for previews"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._ds9_preview_addresses[camera_id].append(address)
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_frame_object(self, object_name):
        """Sets the output frame number"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._frame_object = object_name

            log.info(self._config.log_name, 'Frame object set to ' + object_name)
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_frame_type(self, frame_type):
        """Sets the output frame number"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._frame_type = frame_type

            log.info(self._config.log_name, 'Frame type set to ' + frame_type)
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_wcs(self, enabled):
        """Enable or disable wcs solutions"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._wcs_enabled = enabled
            log.info(self._config.log_name, 'WCS solution ' + ('enabled' if enabled else 'disabled'))
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_hfd(self, enabled):
        """Enable or disable half-flux diameter calculations"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._hfd_enabled = enabled
            log.info(self._config.log_name, 'HFD calculation ' + ('enabled' if enabled else 'disabled'))
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_intensity_stats(self, enabled):
        """Enable or disable intensity statistics solutions"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._intensity_stats_enabled = enabled
            log.info(self._config.log_name, 'Intensity statistics ' + ('enabled' if enabled else 'disabled'))
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard(self, enabled):
        """Enable or disable dashboard updates"""
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._dashboard_enabled = enabled
            log.info(self._config.log_name, 'Dashboard updates ' + ('enabled' if enabled else 'disabled'))
            return CommandStatus.Succeeded

    @Pyro4.expose
    def configure(self, params, quiet=False):
        """Set pipeline configuration to the requested state
           params should be a dictionary with the following keys:
              path: Path where images should be saved
              prefix: Filename prefix for each image
              type: Science/Calibration/Junk/etc
              object: Object name to include for Science frames
              archive: Dictionary of instrument arm to bool for which images to archive
              wcs: Attempt to solve WCS coordinates (True/False)
              intstats: Calculate basic intensity statistics (True/False)
              hfd: Calculate median half-flux diameters from objects in the image (True/False)
              guide: Calculate guide profiles for the given camera
           Any properties not specified in params will be reset to its default
        """
        if not pyro_client_matches(self._config.control_ips):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            directory_status = self.__set_archive_directory(params.get('path', 'default'))
            if directory_status != CommandStatus.Succeeded:
                return directory_status

            if not quiet:
                log.info(self._config.log_name, 'Frame archive directory set to ' + str(self._output_directory))

            self._output_frame_prefix = params.get('prefix', 'unknown')
            if not quiet:
                log.info(self._config.log_name, 'Frame prefix set to ' + self._output_frame_prefix)

            self._frame_type = params.get('type', 'JUNK')
            if not quiet:
                log.info(self._config.log_name, 'Frame type set to ' + self._frame_type)

            self._frame_object = params.get('object', '')
            if not quiet:
                log.info(self._config.log_name, 'Frame object set to ' + self._frame_object)

            for k, v in params.get('archive', {cam: False for cam in self._config.cameras}).items():
                self._output_save_to_disk[k] = v
                if not quiet:
                    log.info(self._config.log_name, 'Frame archiving for ' + k +
                             (' enabled' if v else ' disabled'))

            self._wcs_enabled = params.get('wcs', False)
            if not quiet:
                log.info(self._config.log_name, 'WCS solution ' +
                         ('enabled' if self._wcs_enabled else 'disabled'))

            self._intensity_stats_enabled = params.get('intstats', False)
            if not quiet:
                log.info(self._config.log_name, 'Intensity statistics ' +
                         ('enabled' if self._intensity_stats_enabled else 'disabled'))

            self._hfd_enabled = params.get('hfd', False)
            if not quiet:
                log.info(self._config.log_name, 'HFD calculation ' +
                         ('enabled' if self._hfd_enabled else 'disabled'))

            self._guide_camera_id = params.get('guide', None)
            if not quiet:
                log.info(self._config.log_name, 'Guide profiles ' +
                         ('on ' + self._guide_camera_id if self._guide_camera_id else 'disabled'))

            return CommandStatus.Succeeded

    @Pyro4.expose
    def report_status(self):
        """Returns a dictionary containing the current pipeline state"""
        return {
            'guide_camera_id': self._guide_camera_id,

            'wcs_enabled': self._wcs_enabled,
            'hfd_enabled': self._hfd_enabled,
            'intensity_stats_enabled': self._intensity_stats_enabled,
            'dashboard_enabled': self._dashboard_enabled,

            'archive_enabled': self._output_save_to_disk,
            'archive_directory': str(self._output_directory),

            'frame_type': self._frame_type,
            'frame_object': self._frame_object,
            'frame_prefix': self._output_frame_prefix
        }


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Data pipeline daemon')
    parser.add_argument('config', help='Path to configuration json file')
    args = parser.parse_args()
    c = Config(args.config)
    c.daemon.launch(PipelineDaemon(c))
