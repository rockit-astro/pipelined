#!/usr/bin/env python3
#
# This file is part of pipelined.
#
# pipelined is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# pipelined is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with pipelined.  If not, see <http://www.gnu.org/licenses/>.

"""Daemon for the Warwick one-metre telescope frame pipeline"""

# pylint: disable=too-few-public-methods
# pylint: disable=no-self-use
# pylint: disable=broad-except
# pylint: disable=invalid-name
# pylint: disable=too-many-instance-attributes

import json
import math
import os
from PIL import Image, ImageOps
import re
import shutil
import subprocess
import threading
import time
import numpy
import sep
from astropy.io import fits
import Pyro4
import warwick.observatory as observatory
from warwick.observatory import TryLock

# Set automatically when generating RPM package
SOFTWARE_VERSION = 'UNKNOWN'

PIXELSHIFT_PATH = '/home/saft/src/pixelshift/pixelshift'

GUIDE_REFERENCE_FRAME_PATH = '/var/tmp/guide_reference.fits'

# Matrix coefficients transforming pixel offsets to sky offsets.
# These are just the [CD1_1, CD1_2, CD2_1, CD2_2] wcs parameters
GUIDE_TRANSFORM_MATRICES = {
    'BLUE': [0.000108685545277, -3.58470982799E-07,
             -2.98097156944E-07, -0.000108607868069],
    'RED': [-0.00010858955941, 1.83797853216E-07,
            -2.66674559873E-07, -0.000108601351771]
}

CAMERA_URLS = {
    'BLUE': observatory.daemons.onemetre_blue_camera,
    'RED': observatory.daemons.onemetre_red_camera
}

GUIDE_FUDGE_FACTOR = 0.5

# Time limit (seconds) allowed to solve the WCS coordinates of a preview frame
ANNOTATION_WCS_LIMIT = 2.0

# Maximum field size (arcmin)
ANNOTATION_WCS_SCALE_HIGH = 13.4

# Maximum tcs ra/dec error (degrees)
ANNOTATION_WCS_SEARCH_RADIUS = 1.75

# Unbinned arcseconds per pixel
ANNOTATION_FWHM_PLATESCALE = 0.391

# Minimum number of pixels for considering a source for FWHM estimation
ANNOTATION_FWHM_MINPIX = 16

# Top/bottom margin (in px) to offset the annotation labels
ANNOTATION_LABEL_MARGIN = 30

ANNOTATION_LABEL = 'image; text {} {} #color=green font="helvetica 12 bold" text="{}" select=0'

# This should be kept in sync with the dictionary in pipeline
class CommandStatus:
    """Numeric return codes"""
    # General error codes
    Succeeded = 0
    Failed = 1
    Blocked = 2

def rescale_image_data(data, clip_low, clip_high):
    """ Returns a normalised array where clip_low percent of the pixels are 0 and
        clip_high percent of the pixels are 255
    """
    high = numpy.percentile(data, clip_high)
    low = numpy.percentile(data, clip_low)
    scale = 255. / (high - low)
    data = numpy.clip(data, low, high)
    return scale * (data - low)

class PipelineDaemon:
    """Daemon interface for data pipeline"""
    def __init__(self):
        self._command_lock = threading.Lock()
        self._guide_condition = threading.Condition()
        self._guide_camera_id = None
        self._guide_latest_frame = None
        self._guide_x_binning = 1
        self._guide_y_binning = 1
        self._guide_cos_dec = 1
        self._guide_background_tile_size = 0
        self._guide_reference_frame = None
        self._guide_last_guide_frame = None

        guide_thread = threading.Thread(target=self.__process_guide_frames)
        guide_thread.daemon = True
        guide_thread.start()

        self._reduction_condition = threading.Condition()
        self._reduction_enabled = False
        self._reduction_files = set()

        reduction_thread = threading.Thread(target=self.__update_reduction)
        reduction_thread.daemon = True
        reduction_thread.start()

        self._annotations_condition = threading.Condition()
        self._annotations_enabled = True
        self._annotations_files = set()

        annotations_thread = threading.Thread(target=self.__update_annotations)
        annotations_thread.daemon = True
        annotations_thread.start()

        self._dashboard_condition = threading.Condition()
        self._dashboard_enabled = False
        self._dashboard_update_blue = None
        self._dashboard_update_red = None

        # Min and max percentage thresholds to use for the preview pngs
        self._dashboard_min_threshold = 5
        self._dashboard_max_threshold = 95
        self._dashboard_thumb_size = 512

        dashboard_thread = threading.Thread(target=self.__update_dashboard_data)
        dashboard_thread.daemon = True
        dashboard_thread.start()

    def __process_guide_frames(self):
        """Calculates image shifts between frames and offsets telescope to compensate"""
        while True:
            # Block until a frame is available for processing
            frame = None
            with self._guide_condition:
                while self._guide_latest_frame is None:
                    self._guide_condition.wait()

                frame = self._guide_latest_frame
                self._guide_latest_frame = None

            # New guide session: take a copy of this frame to use as the reference
            if self._guide_reference_frame is None:
                print('taking', frame, 'as new guide reference')
                observatory.log.info('pipelined', 'Initializing autoguider')
                try:
                    self._guide_reference_frame = GUIDE_REFERENCE_FRAME_PATH
                    shutil.copy(frame, GUIDE_REFERENCE_FRAME_PATH)
                    reference = fits.open(GUIDE_REFERENCE_FRAME_PATH)
                    self._guide_x_binning = reference[0].header['CCD-XBIN']
                    self._guide_y_binning = reference[0].header['CCD-YBIN']

                    # RA becomes compressed away from the equator
                    # Calculate the correction scale factor
                    dec = reference[0].header['TELDEC']
                    parts = dec.split(':')

                    # Sign doesn't matter, so discard immediately
                    a = abs(float(parts[0]))
                    b = float(parts[1])
                    c = float(parts[2])
                    self._guide_cos_dec = math.cos((a + b / 60 + c / 3600) * math.pi / 180)

                    reference.close()
                except Exception as e:
                    print('failed with error: ' + str(e))
                    observatory.log.error('pipelined', 'Failed to initialize autoguider (' \
                                          + str(e) + ')')
                continue

            if self._guide_camera_id not in GUIDE_TRANSFORM_MATRICES:
                print('no transform matrix for camera ' + self._guide_camera_id)
                continue

            try:
                output = subprocess.check_output(
                    [PIXELSHIFT_PATH, frame, self._guide_reference_frame,
                     str(self._guide_background_tile_size)], universal_newlines=True, timeout=5)

                t = GUIDE_TRANSFORM_MATRICES[self._guide_camera_id]
                coords = output.split(' ')

                # Measured offset in px
                dx = float(coords[0])
                dy = float(coords[1])

                # First-order approximated offset in ra, dec (degrees)
                dra = (t[0] * dx + t[1] * dy) * self._guide_x_binning / self._guide_cos_dec
                ddec = (t[2] * dx + t[3] * dy) * self._guide_y_binning

                # Calculate actual telescope offset by running offsets through PID loop
                # TODO: This currently only accounts for proportional offsets (no history)
                guide_offset_ra = GUIDE_FUDGE_FACTOR * dra * math.pi / 180
                guide_offset_dec = GUIDE_FUDGE_FACTOR * ddec * math.pi / 180

                # TODO: Check for and drop anomalously large offsets

                print('offset px: {} {}; arcsec: {} {}'.format(dx, dy, 3600 * dra, 3600 * ddec))

                with observatory.daemons.onemetre_telescope.connect() as teld:
                    teld.offset_radec_guiding(guide_offset_ra, guide_offset_dec)
            except Exception as e:
                print('failed to update guiding with error: ' + str(e))
                observatory.log.error('pipelined', 'Failed to calculate guide offset (' \
                                      + str(e) + ')')

    def __update_reduction(self):
        """Updates the online reduction as frames are saved to disk"""
        while True:
            # Block until a frame is available for processing
            updated = None
            with self._reduction_condition:
                while len(self._reduction_files) == 0:
                    self._reduction_condition.wait()

                updated = self._reduction_files.copy()
                self._reduction_files.clear()

            for f in updated:
                print('will update reduction file `' + f + '` if it exists')
                if not os.path.isfile(f):
                    continue

                # TODO: Integrate reduction into the pipeline better
                try:
                    subprocess.check_call(['/home/saft/src/tsreduce/tsreduce', 'update', f])
                    subprocess.check_call(['/home/saft/src/tsreduce/tsreduce', 'plot', f])
                except Exception as e:
                    print('failed to update reduction with error: ' + str(e))

    def __update_dashboard_data(self):
        """Generates the png and json files displayed in the web dashboard"""
        while True:
            # Block until a frame is available for processing
            updated = []
            with self._dashboard_condition:
                while self._dashboard_update_blue is None and \
                        self._dashboard_update_red is None:
                    self._dashboard_condition.wait()

                if self._dashboard_update_blue is not None:
                    updated.append(self._dashboard_update_blue)
                    self._dashboard_update_blue = None

                if self._dashboard_update_red is not None:
                    updated.append(self._dashboard_update_red)
                    self._dashboard_update_red = None

            for path in updated:
                try:
                    with fits.open(path) as frame:
                        h = frame[0].header

                        # Trim overscan regions
                        r = re.search(r'^\[(\d+):(\d+),(\d+):(\d+)\]$', h['IMAG-RGN']).groups()
                        data = frame[0].data[int(r[2])-1:int(r[3]), int(r[0])-1:int(r[1])]

                        arm = h['INSTRARM']
                        metadata = {
                            'date': h['DATE-OBS'],
                            'exptime': h['EXPTIME'],
                            'saved': h['FILESAVE'],
                            'filename': h['FILENAME'],
                        }

                    scaled = rescale_image_data(data, self._dashboard_min_threshold,
                                                self._dashboard_max_threshold)
                    png = Image.fromarray(scaled).convert('RGB')

                    # Red arm flips vertically only
                    # Blue arm flips horizontally and vertically
                    png = ImageOps.flip(png)
                    if arm == 'BLUE':
                        png = ImageOps.mirror(png)

                    png.save('/var/tmp/dashboard-' + arm + '.png', "PNG", clobber=True)
                    png.thumbnail((self._dashboard_thumb_size, self._dashboard_thumb_size))
                    png.save('/var/tmp/dashboard-' + arm + '-thumb.png', "PNG", clobber=True)
                    with open('/var/tmp/dashboard-' + arm + '.json', 'w') as outfile:
                        json.dump(metadata, outfile)
                except Exception as e:
                    print('failed to generate dashboard preview with error: ' + str(e))
                    observatory.log.error('pipelined', 'Failed to generate dashboard data (' \
                                          + str(e) + ')')

    def __generate_header_annotations(self, frame):
        """Returns the XPA commands to display the time and exposure on the live previews"""
        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']
        date = frame.header['DATE-OBS']
        exptime = frame.header['EXPTIME']
        arm = frame.header['INSTRARM']

        return [
            ('regions', ANNOTATION_LABEL.format(width / 4, height + ANNOTATION_LABEL_MARGIN, date)),
            ('regions', ANNOTATION_LABEL.format(3 * width / 4, height + ANNOTATION_LABEL_MARGIN,
                                                '{} @ {:.1f}s'.format(arm, exptime)))
        ]

    def __generate_wcs_annotations(self, frame, path):
        """Solves the frame WCS and returns the XPA commands to run on the live previews"""
        width = frame.header['NAXIS1']
        try:
            frame_ra = frame.header['TELRA']
            frame_dec = frame.header['TELDEC']

            if frame.header['SHUTTER'] == 'CLOSED':
                return []

            args = [
                '/usr/local/astrometry/bin/solve-field',
                '--no-fits2fits', '--overwrite', '--no-plots',
                '--axy', 'none', '--rdls', 'none', '--match', 'none',
                '--corr', 'none', '--index-xyls', 'none',
                '--solved', 'none', '--scale-units', 'arcminwidth',
                '--scale-high', str(ANNOTATION_WCS_SCALE_HIGH),
                '--ra', frame_ra, '--dec', frame_dec,
                '--radius', str(ANNOTATION_WCS_SEARCH_RADIUS), path]

            subprocess.check_call(args, timeout=ANNOTATION_WCS_LIMIT,
                                  stdout=subprocess.DEVNULL,
                                  stderr=subprocess.DEVNULL)

            wcs_data = ''
            wcs_ignore_cards = ['SIMPLE', 'BITPIX', 'NAXIS', 'EXTEND', 'DATE']
            with open(os.path.splitext(path)[0] + '.wcs') as wcs_file:
                header = wcs_file.read()
                # ds9 will only accept newline-delimited keys
                # so we need to reformat the 80-character cards
                for line in [header[i:i+80] for i in range(0, len(header), 80)]:
                    key = line[0:8].strip()
                    if '=' in line and key not in wcs_ignore_cards:
                        # Strip unnecessary whitespace and comments
                        value = line[9:].split('/')[0].strip()
                        wcs_data += key + ' = ' + value + '\n'
            return [
                ('wcs replace', wcs_data),
                ('regions', ANNOTATION_LABEL.format(width / 4, -ANNOTATION_LABEL_MARGIN,
                                                    'WCS: solved'))
            ]

        except Exception as e:
            print('failed to update wcs with error: ' + str(e))
            return [('regions', ANNOTATION_LABEL.format(width / 4, -ANNOTATION_LABEL_MARGIN,
                                                        'WCS: failed'))]

    def __generate_fwhm_annotations(self, frame, path):
        """Estimates and the median PSF FWHM and returns the XPA
           commands to run on the live previews"""
        width = frame.header['NAXIS1']
        try:
            if frame.header['SHUTTER'] == 'CLOSED':
                return []

            platescale = frame.header['CCD-XBIN'] * ANNOTATION_FWHM_PLATESCALE
            image = fits.getdata(path).astype(float)
            bkg = sep.Background(image)
            subtracted = image - bkg

            thresh = 5 * bkg.globalrms
            objects = sep.extract(subtracted, thresh)
            fwhm = []
            commands = []
            for star in objects:
                # Discard spuriously small sources
                if star['npix'] < ANNOTATION_FWHM_MINPIX:
                    continue

                x = star['x']
                y = star['y']
                a = star['a']
                b = star['b']
                theta = star['theta']
                kronrad, flag = sep.kron_radius(subtracted, x, y, a, b, theta, 6.0)
                if flag != 0:
                    continue

                flux, fluxerr, flag = sep.sum_ellipse(subtracted, x, y, a, b, theta,
                                                      2.5 * kronrad, subpix=1)
                if flag != 0:
                    continue

                r, flag = sep.flux_radius(subtracted, x, y, 6.0 * a, 0.5, normflux=flux, subpix=5)
                if flag != 0:
                    continue

                fwhm.append(2 * r * platescale)
                commands.append(('regions', 'image; circle({},{},{}) #select=0 color=red'.format(
                    x + 1, y + 1, r)))

            if len(fwhm) > 0:
                median = numpy.median(fwhm)
                label = 'FWHM: {:.1f} arcsec'.format(median)
            else:
                label = 'FWHM: failed'
            commands.append(('regions', ANNOTATION_LABEL.format(3 * width / 4,
                                                                -ANNOTATION_LABEL_MARGIN,
                                                                label)))
            return commands
        except Exception as e:
            print('failed to calculate fwhm with error: ' + str(e))
            return [('regions', ANNOTATION_LABEL.format(3 * width / 4, -ANNOTATION_LABEL_MARGIN,
                                                        'FWHM: failed'))]

    def __update_annotations(self):
        """Calculates WCS solutions and median seeing for the latest frame previews.
           Also updates web dashboard preview"""
        while True:
            # Block until a frame is available for processing
            updated = None
            with self._annotations_condition:
                while len(self._annotations_files) == 0:
                    self._annotations_condition.wait()

                updated = self._annotations_files.copy()
                self._annotations_files.clear()

            # Force a small delay to avoid racing against the camera's frame update
            time.sleep(1.0)
            for camera_id, path in updated:
                if camera_id not in CAMERA_URLS:
                    print('no pyro address for camera ' + camera_id)
                    return

                # List of XPA commands to run on the frame previews
                with fits.open(path) as frame:
                    preview_commands = self.__generate_header_annotations(frame[0])
                    preview_commands.extend(self.__generate_wcs_annotations(frame[0], path))
                    preview_commands.extend(self.__generate_fwhm_annotations(frame[0], path))

                try:
                    with CAMERA_URLS[camera_id].connect() as camd:
                        camd.update_previews(preview_commands)
                        print('updated preview annotations')
                except Exception as e:
                    print('failed to update preview annotations with error: ' + str(e))

    @Pyro4.expose
    def notify_latest_frame(self, camera_id, path):
        """Called by the camera daemons to notify that the latest frame file has been updated"""
        if self._guide_camera_id == camera_id:
            # The guiding only cares about the latest frame
            with self._guide_condition:
                self._guide_latest_frame = path
                self._guide_condition.notify()
            print('updated latest frame', camera_id, path)

        if self._annotations_enabled:
            with self._annotations_condition:
                self._annotations_files.add((camera_id, path))
                self._annotations_condition.notify()

        with self._dashboard_condition:
            if camera_id == 'BLUE':
                self._dashboard_update_blue = path
            elif camera_id == 'RED':
                self._dashboard_update_red = path
            self._dashboard_condition.notify()

    @Pyro4.expose
    def notify_saved_frame(self, camera_id, path):
        """Called by the camera daemons to notify that a new frame has been saved to disk"""
        if not self._reduction_enabled:
            return

        # The current version of the reduction code doesn't care about the individual
        # frame names - only the name of the tsreduce reduction file.  The reduction file
        # is expected to be in the frame save dir with a filename matching the frame prefix.
        reduction_file = path.rpartition('-')[0] + '.dat'
        with self._reduction_condition:
            self._reduction_files.add(reduction_file)
            self._reduction_condition.notify()

    @Pyro4.expose
    def set_guide_camera(self, camera_id, background_tile_size=0):
        """Sets the camera ID to use for guiding"""
        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._guide_camera_id = camera_id
            self._guide_background_tile_size = background_tile_size
            self._guide_reference_frame = None
            self._guide_last_guide_frame = None
            observatory.log.info('pipelined', 'Configured autoguiding with ' + camera_id \
                                 + ' camera and ' + str(background_tile_size) + ' px tiles')
            return CommandStatus.Succeeded

    @Pyro4.expose
    def enable_reduction(self, enabled):
        """Enable or disable the online reduction"""
        self._reduction_enabled = enabled
        observatory.log.info('pipelined', 'Reduction ' + ('enabled' if enabled else 'disabled'))
        return CommandStatus.Succeeded

    @Pyro4.expose
    def enable_annotations(self, enabled):
        """Enable or disable the live preview annotations"""
        self._annotations_enabled = enabled
        observatory.log.info('pipelined', 'Preview annotations ' \
                             + ('enabled' if enabled else 'disabled'))
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_min_threshold(self, percent):
        """Sets the minimum contrast percentage for the web dashboard preview"""
        self._dashboard_min_threshold = percent
        observatory.log.info('pipelined', 'Dashboard preview min threshold set to ' \
                             + str(percent) + '%')
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_max_threshold(self, percent):
        """Sets the maximum contrast percentage for the web dashboard preview"""
        self._dashboard_max_threshold = percent
        observatory.log.info('pipelined', 'Dashboard preview min threshold set to ' \
                             + str(percent) + '%')
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_thumb_size(self, max_size):
        """Sets the maximum dimension of the web dashboard preview thumbnails"""
        self._dashboard_thumb_size = max_size
        observatory.log.info('pipelined', 'Dashboard preview thumbnail size set to ' \
                             + str(max_size) + ' px')
        return CommandStatus.Succeeded

    @Pyro4.expose
    def report_status(self):
        """Returns a dictionary containing the current pipeline state"""
        return {
            'reduction_enabled': self._reduction_enabled,
            'annotations_enabled': self._annotations_enabled,
            'guide_camera_id': self._guide_camera_id,
            'guide_background_tile_size': self._guide_background_tile_size,
            'guide_reference_frame': self._guide_reference_frame,
            'guide_last_guide_frame': self._guide_last_guide_frame,

            'dashboard_min_threshold': self._dashboard_min_threshold,
            'dashboard_max_threshold': self._dashboard_max_threshold,
            'dashboard_thumb_size': self._dashboard_thumb_size
        }

if __name__ == '__main__':
    observatory.daemons.onemetre_pipeline.launch(PipelineDaemon())
